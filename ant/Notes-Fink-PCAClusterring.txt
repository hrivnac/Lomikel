# data preparation
# @janusgraph
work/preparePCA.gremlin
# @home
scp centos@134.158.74.85:'/tmp/*.csv' ./
scp *csv julius.hrivnac@vm-75222.lal.in2p3.fr:'/tmp'

# @livy
git pull;hadoop fs -put -f ../src/work/PCA.py;hadoop fs -put -f PCA-sample.csv /tmp

# @janusgraph
lomikel_hbase -s PCA.groovy  

# @home
scp julius.hrivnac@vm-75222.lal.in2p3.fr:/tmp/'*.png' ./
scp julius.hrivnac@vm-75222.lal.in2p3.fr:/tmp/'*.json' ./
scp *json centos@134.158.74.85:/tmp

# @janusgraph (gremlin)
gr.generateCorrelations(Classifiers.valueOf("FEATURES"), Classifiers.valueOf("FINK_PORTAL"))
csv = "type1,classifier1,class1,type2,classifier2,class2,overlap\n"
gr.overlaps().each{o -> csv += o.getKey().replaceAll(" \\* ", ",").replaceAll(":", ",") + "," + o.getValue() + "\n"}
new File("/tmp/overlaps.csv").text=csv

# @home
scp centos@134.158.74.85:/tmp/overlaps.csv ./
python ../src/work/analysePCA.py

--------------------------------------------------------------------------------

preparePCA.gremlin
------------------
n_cls = 1000
n_objectId = 1000
min_jd = 100
max_jd = 100

cleaning

=> n_pca = 13

...
n_clusters = 11

 "+-------+-----+",
    "|cluster|count|",
    "+-------+-----+",
    "|     10| 1368|",
    "|      8|  389|",
    "|      9|  381|",
    "|      6|  548|",
    "|      4|  327|",
    "|      0|  467|",
    "|      2|  169|",
    "|      1| 1157|",
    "|      3| 1042|",
    "|      5|  487|",
    "|      7|    6|",
    "+-------+-----+",
    
    --------------------------------------------------------------------------------
